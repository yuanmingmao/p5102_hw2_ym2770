Homework 2
================
Yuanming Mao

``` r
library(tidyverse)
```

    ## ── Attaching packages ──────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ─────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df =
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2018 and 2017.

``` r
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1,
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)


precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1,
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation.

``` r
month_df =
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df =
  bind_rows(precip_2018, precip_2017)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash.

The **trashwheel\_df** dataset has 344 observations. It includes date of
trash collection for each dumpster, weight and volume of trash
collected, and the number of specific types of trash.

The **precip\_df** dataset includes month precipitation data, and has 24
observations.

For available data, the total precipitation in 2018 was 70.33 inches.
The median number of sports balls in a dumpster in 2017 was 8.

## problem 2

Read NYC Transit data

``` r
transit_df = 
  read.csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:ada, -exit_only, -staffing, -staff_hours) %>% 
  mutate(entry = recode(entry, "YES" = 1, "NO" = 0)) %>% 
  mutate(entry = as.logical(entry)) %>% 
  mutate(vending = recode(vending, "YES" = 1, "NO" = 0)) %>% 
  mutate(vending = as.logical(vending))
```

The **transit\_df** dataset contains information about each NYC subway
station, which includes station name, line, station latitude /
longitude, each route served, whether entry is allowed, whether vending
is available, entrance type, and ADA compliance.

`janitor::clean_names()` is used to clean up variable names after
importing data. Using `select()`, columns from line variable to ada
variable are included, and unneded variables among those columns are
removed including exit\_only, staffing, and staff\_hours. The entry
variable and vending variable are converted from character (YES vs NO)
to logical variables. These data are not tidy enough. The route names
spread across 11 columns, which correspond to several route numbers.
`pivot_longer()` is needed to further tidy the dataset.

The resulting dataset has 1868 rows and 19 columns.

There are 465 distinct stations.

84 stations are ADA compliant.

37.704918% of station entrances / exits without vending allow entrance.

Reformat data so that route number and route name are distinct
variables.

``` r
transit_tidy_data = 
  transit_df %>% 
  mutate_at(vars(route1:route11), as.character) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    names_prefix = "route",
    values_to = "route_number"
  )
```

60 distinct stations serve the A train.

17 stations that serve the A train are ADA compliant.

## problem 3

First, import and clean the data in pols-month dataset.

``` r
pols_df = 
  read.csv("./data/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon,into = c("year", "month", "day"), sep = "-", convert = TRUE) %>% 
  left_join( month_df, by = "month") %>% 
  select(-month) %>% 
  relocate(year, month_name, everything()) %>% 
  rename(month = month_name) %>% 
  mutate(president = case_when(
    prez_dem == 1 ~"dem",
    prez_gop == 1 ~ "gop"
  )) %>% 
  select(-prez_dem, -prez_gop) %>% 
  select(-day)

# prez_gop variable has three possible values (0, 1, 2). Since the meaning of 2 hasn't been specified, I leave it as NA in president variable.
```

Second, import and clean the data in snp dataset.

``` r
snp_df = 
  read.csv("./data/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date,into = c("month", "day", "year"), sep = "/", convert = TRUE) %>% 
  left_join( month_df, by = "month") %>% 
  select(-month) %>% 
  relocate(year, month_name, everything()) %>% 
  rename(month = month_name) %>% 
  select(-day) %>% 
  arrange(year, month)
```

Third, import and tidy the unemployment data

``` r
unemploy_df = 
  read.csv("./data/unemployment.csv") %>% 
  rename(January = Jan, 
         February = Feb,
         March = Mar,
         April = Apr,
         May = May,
         June = Jun,
         July = Jul,
         August = Aug,
         September = Sep,
         October = Oct,
         November = Nov,
         December = Dec) %>% 
  pivot_longer(
    January:December,
    names_to = "month",
    values_to = "unemployment"
  ) %>% 
  rename(year = Year)
```

Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
final_data_df = 
  left_join(pols_df, snp_df, by = c("year","month")) %>% 
  left_join(unemploy_df, by = c("year","month"))
```

The **pols\_df** dataset contains information about the number of
national politicians who are democratic or republican at any given year
and month from year 1947 to 2015. Key variables include the number of
governors, senators, and representatives from each political party, as
well as the political party of president in any given year and month.
The dataset has 822 rows and 9 columns.

The **snp\_df** dataset contains information on closing values of
Standard & Poor’s stock market index (S\&P) in any given year and month
from year 1950 to 2015. Key variables include year, month, and the
corresponding closing values. The dataset has 787 rows and 3 columns.

The **unemploy\_df** dataset contains information on unployment
percentage in any given year and month from year 1948 to 2015. Key
variables include year, month, and corresponding percentage of
unemployment. The dataset has 816 rows and 3 columns.

The **final\_data\_df** dataset is generated by merging **pols\_df**,
**snp\_df**, and **unemploy\_df** datasets by year and month. It
contains information on numbers of national politicians in each
political party, the political party of president, closing values of
Standard & Poor’s stock market index, and unemployment percentage in any
given year and month from 1947 to 2015. The dataset has 822 rows and 11
columns.
